# âœˆï¸ Airflow Docker Project â€“ PostgreSQL & MySQL Integration

This project sets up an Apache Airflow environment using Docker Compose with support for:

- PostgreSQL as the metadata database
- MySQL as a data source (e.g., `flight_staging`)
- Custom configuration and Python packages
- A clean structure for DAGs, plugins, and configs

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/                    # Custom config modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ dags/                      # DAGs live here
â”‚   â””â”€â”€flight_price_pipeline.py
â”œâ”€â”€ diagram/                   # Architecture diagram
â”œâ”€â”€ docker/
â”‚       â””â”€â”€mysql               # Database and configurations
â”œâ”€â”€ plugins/                   # Custom operators, helpers, etc.
â”œâ”€â”€ scrrenshots/               # Screenshots of the Airflow UI
â”œâ”€â”€ data/                      # Any input/output data
â”œâ”€â”€ logs/                      # Airflow logs
â”œâ”€â”€ docker-compose.yml         # Docker Compose services
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                 # Custom Airflow image
â””â”€â”€ README.md
```

---

## ğŸš€ Features

- **PostgreSQL**: Metadata database for Airflow.
- **MySQL**: Staging database initialized via `init.sql`.
- **Custom Configuration**: Use `config/settings.py` in DAGs via clean import paths.
- **LocalExecutor**: Run tasks in parallel for small to medium workloads.
- **Basic Auth**: Log in via username/password (`admin:admin` by default).

---

## ğŸ› ï¸ Prerequisites

- Docker & Docker Compose installed

---

## ğŸ”§ Configuration

### `Dockerfile`

Custom image built from `apache/airflow:2.8.1-python3.10`, extended with required system packages and custom modules:

```dockerfile
FROM apache/airflow:2.8.1-python3.10

USER root
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    default-libmysqlclient-dev \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

USER airflow

COPY ./dags /opt/airflow/dags
COPY ./plugins /opt/airflow/plugins
COPY ./config /opt/airflow/config

ENV PYTHONPATH="${PYTHONPATH}:/opt/airflow/config:/opt/airflow/plugins"
```

### Docker Compose Environment (`docker-compose.yml`)

Key settings include:

- PostgreSQL container with health check
- MySQL container initialized with an SQL script
- Airflow Webserver and Scheduler sharing code/config
- PYTHONPATH correctly set for custom imports

Update:

```yaml
- AIRFLOW__CORE__PYTHONPATH=/opt/airflow/config:/opt/airflow/plugins
```

---

## ğŸ§ª Getting Started

1. **Clone the repository**

   ```bash
   git clone https://github.com/your-repo/airflow-docker-mysql-postgres.git
   cd airflow-docker-mysql-postgres
   ```

2. **Create init files if missing**

   ```bash
   touch config/__init__.py
   ```

3. **Build & run containers**

   ```bash
   docker-compose down --volumes --remove-orphans
   docker-compose build
   docker-compose up
   ```

4. **Access Airflow UI**  
   Go to [http://localhost:8080](http://localhost:8080)  
   Login:
   - Username: `admin`
   - Password: `admin`

---

## âœ… DAG Example

In any DAG, you can safely import config like this:

```python
from config.settings import settings
```

Make sure `settings.py` contains your structured configuration, e.g.,:

```python
# config/settings.py
settings = {
    "source_db": "mysql",
    "target_db": "postgres"
}
```

---

## ğŸ§¹ Cleaning Up

Stop and remove all containers and volumes:

```bash
docker-compose down --volumes --remove-orphans
```

---

## ğŸ“¬ Feedback & Contribution

Feel free to fork, improve, and submit pull requests. For issues, please open a GitHub issue.

---

## ğŸ“„ License

MIT License. See `LICENSE` file.
